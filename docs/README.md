# ğŸ§  Context â€“ Your AI Powered Study Assistant

**Context** is a local AI assistant for students. It lets you upload your study materials (PDFs, slides, notes) and ask natural language questions about them. Powered by LangChain, FAISS, and modern LLMs, Context gives grounded answers based on your files â€” with full privacy and local control.

---

## ğŸš€ Features

- ğŸ“¥ Upload PDFs, DOCX, TXT, or Markdown files
  
- âœ‚ï¸ Automatically splits documents into semantic chunks
  
- ğŸ”¢ Embeds content with OpenAI or local models
  
- ğŸ“š Stores vectors in FAISS for fast local retrieval
  
- ğŸ” Ask questions in plain English, get answers based on your data
  
- ğŸ§  Powered by Retrieval-Augmented Generation (RAG)

- ğŸ’» Simple UI built with Streamlit

---

## ğŸ“¦ Tech Stack

| Component        | Tool/Library                    |
|------------------|----------------------------------|
| File Handling    | `LangChain.document_loaders`     |
| Chunking         | `RecursiveCharacterTextSplitter` |
| Embeddings       | `OpenAIEmbeddings`, `HuggingFaceEmbeddings` |
| Vector Store     | `FAISS`                          |
| Language Models  | `OpenAI`, `local LLMs via Ollama` |
| UI               | `Streamlit`                      |

---

## ğŸ” file processing pipeline

```
1. Loading
   â†“ load files using LangChain loaders

2. Splitting
   â†“ chunk files using LangChain splitters

3. Embedding
   â†“ embed chunks using OpenAI embedder

4. Vector Store
   â†“ create/load FAISS vector store

5. Retrieval
   â†“ handle queries and retrieve top-k chunks
```

---

## ğŸ“ Project Structure

<pre>
context-app/
â”œâ”€â”€ main.py                  # App entry point
â”œâ”€â”€ config.py                # API keys, constants
â”œâ”€â”€ requirements.txt         # Dependencies
â”‚
â”œâ”€â”€ ingestion/               # File loading & chunking
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ splitter.py
â”‚
â”œâ”€â”€ embedding/               # Embedding and vector store
â”‚   â”œâ”€â”€ embedder.py
â”‚   â””â”€â”€ vector_store.py
â”‚
â”œâ”€â”€ retrieval/               # Chunk retriever
â”‚   â””â”€â”€ retriever.py
â”‚
â”œâ”€â”€ generation/              # Prompt + LLM logic
â”‚   â””â”€â”€ rag_chain.py
â”‚
â”œâ”€â”€ ui/                      # User interface
â”‚   â””â”€â”€ interface.py
â”‚
â””â”€â”€ utils/                   # Helper functions
    â””â”€â”€ helpers.py
</pre>


---

## âš¡ Getting Started

### 1. Clone the repo
```bash
git clone https://github.com/your-username/context-app.git
cd context-app
```
### 2. Install dependencies
```bash
pip install -r requirements.txt
```
### 3. Add your OpenAI key (or use a local model)
```bash
in config.py OPENAI_API_KEY = "your-key-here"
```
### 4. Run the app
```bash
streamlit run main.py
```
